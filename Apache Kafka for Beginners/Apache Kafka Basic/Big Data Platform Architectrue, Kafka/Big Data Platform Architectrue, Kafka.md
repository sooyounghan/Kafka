-----
### 빅 데이터 플랫폼 아키텍쳐와 카프카
-----
1. 초기 : End-to-End
<div align="center">
<img src="https://github.com/user-attachments/assets/0f203bb2-ddcf-485e-a37f-376f45bb734b">
</div>

   - 각 서비스 애플리케이션으로부터 데이터를 배치로 모음
   - 데이터를 배치로 모으는 구조는 유연하지 못하며, 실시간으로 생성되는 데이터들에 대한 인사이트를 서비스 애플리케이션에 빠르게 전달하지 못하는 단점 존재
   - 또한, 원천 데이터부터 파생된 데이터의 히스토리를 파악하기 어려우며, 계속되는 데이터 가공으로 인해 데이터가 파편화되어 데이터 거버넌스(Governance)를 지키기 어려웠음
     + 거버넌스(Governance) : 빅데이터에 대한 체계적 관리와 통제를 의미 (예) 프라이버시, 품질, 데이터 생명주기 등을 의미)

2. 이러한 단점을 해결하고자 나온 것 : 람다 아키텍쳐(Lambda Architecture)
   - 3가지 레이어로 구성 : 배치 레이어, 서빙 레이어, 스피드 레이
<div align="center">
<img src="https://github.com/user-attachments/assets/5717556e-614f-4414-beff-4c1868a3057a">
</div>

   - 배치 레이어 : 배치 데이터를 모아서 특정 시간, 타이밍 마다 일괄처리 (Spark Job과 같은 대규모 배치 잡의 동작)
   - 서빙 레이어 : 가공된 데이터를 데이터 사용자, 서비스 애플리케이션이 사용할 수 있도록 데이터가 저장된 공간 (예) 하둡(Hadoop)과 같은 대용량 데이터를 안정적으로 저장)
   - 스피드 레이어 : 서비스에서 생성되는 원천 데이터를 실시간으로 분석하는 용도로 사용 (배치 데이터에 비해 낮은 지연으로 분석이 필요한 경우 이를 통해 데이터를 분석, 카프카와 같은 이벤트 스트리밍 플랫폼)
   - 한계 : 데이터를 배치 처리하는 레이어와 실시가 처리하는 레이어를 분리하였으므로 데이터 처리 방식을 명확히 나눌 수 있지만, 레이어가 2개로 나눠지면서 단점 발생
     + 데이터를 분석, 처리하는데 필요한 로직이 2개로, 각 레이어에 따로 존재해야 함 (로직의 파편화)
     + 배치 데이터와 실시간 데이터를 융합하여 처리할 때는 다소 유연하지 못한 파이프라인을 생성해야 함 : 1개의 로직을 추상화하여 배치 레이어와 스피드 레이어에 적용하는 형태인 서밍버드라는 플랫폼이 존재하지만, 완벽하게 해결되지 않음 (컴파일을 한 번만 수행하더라도, 배포는 2번, 디버링 / 로깅 / 모니터링도 분리되는 이슈 발생)

3. 카파 아키텍쳐 (Kappa Arcitecture) : 람다 아키텍쳐를 해결하고자 나온 최근 빅데이터 처리에서 주목받는 혁신적 데이터 엔지니어링 프레임워크
   - 배치 레이어를 제거하는 방안
<div align="center">
<img src="https://github.com/user-attachments/assets/23e1449c-6f46-4f30-a0f8-690f929323ad">
</div>

   - 스피드 레이어에서 데이터를 모두 처리할 수 있으므로, 엔지니어들이 더욱 효율적으로 개발과 운영에 임하게 함

4. 스트리밍 데이터 레이크 (Streaming Data Lake)
   - 카파 아키텍쳐에서 서빙 레이어를 제거한 형태
<div align="center">
<img src="https://github.com/user-attachments/assets/060ab38e-a546-4a98-ba25-efe8441135db">
</div>

   - 데이터를 사용하는 고객을 위해 스트림 데이터를 서빙 레이어에 저장
   - 스피드 레이어로 사용되는 카프카에게 분석과 프로세싱을 완료한 거대한 용량의 데이터를 오랜 기간 저장하고 사용해야 한다면, 서빙 레이어는 제거되어도 무방하다고 판단
   - 오히려 서빙 레이와 스피드 레이어가 이중으로 관리되는 운영 리소스를 줄일 수 있는 것
   - 개선 사항
     + 스트리밍 데이터를 배치 데이터로 자유롭게 접근 가능해야 함 : 스트리밍 데이터는 타임스탬프를 기준으로 쿼리를 돌려 배치형태로 데이터를 일부 뽑아낼 수 있지만, 아파치 카파카는 한계 존재 - 확장성 문제에 대해서는 더 많은 개선 필요
     + 자주 접근하지 않는 데이터를 굳이 비싼 자원에 유지할 필요가 없음 : 카프카 클러스터에서 자주 접근하지 않는 데이터는 오히려 오브젝트 스토리지와 같은 저렴하면서도 안전한 저장소에 옮겨 저장하고, 자주 사용하는 데이터만 브로커에서 사용하는 구분 작업이 필요 
